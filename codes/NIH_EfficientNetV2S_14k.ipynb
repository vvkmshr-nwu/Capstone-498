{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NIH Chest X-ray Dataset Explanation\n",
    "\n",
    "## Introduction\n",
    "The **NIH Chest X-ray Dataset** is a large-scale dataset provided by the National Institutes of Health (NIH), containing **112,120 frontal-view chest X-ray images** from **30,805 unique patients**. The dataset was introduced to support the development of deep learning models for automated diagnosis of thoracic diseases.\n",
    "\n",
    "## Key Features\n",
    "- **Large-scale dataset**: Contains over 112,000 X-ray images.\n",
    "- **Multi-label classification**: Includes annotations for **14 different thoracic diseases**, such as pneumonia, edema, emphysema, and fibrosis.\n",
    "- **Metadata Availability**: Includes patient age, gender, view position, and image index.\n",
    "- **Open-Source**: Publicly available for research and development in medical AI applications.\n",
    "\n",
    "## Labels and Diseases\n",
    "The dataset provides labels for the following 14 thoracic conditions:\n",
    "- Atelectasis\n",
    "- Cardiomegaly\n",
    "- Consolidation\n",
    "- Edema\n",
    "- Effusion\n",
    "- Emphysema\n",
    "- Fibrosis\n",
    "- Hernia\n",
    "- Infiltration\n",
    "- Mass\n",
    "- Nodule\n",
    "- Pleural Thickening\n",
    "- Pneumonia\n",
    "- Pneumothorax\n",
    "\n",
    "```\n",
    "\n",
    "## Applications\n",
    "- **Automated disease diagnosis** using deep learning models.\n",
    "- **Medical AI research** for improving diagnostic accuracy.\n",
    "- **Explainability and interpretability studies** to analyze model decision-making.\n",
    "\n",
    "The NIH Chest X-ray Dataset has been widely used in medical imaging research, contributing to advancements in AI-powered diagnostics.\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EfficientNetV2S Model Explanation\n",
    "\n",
    "## Introduction\n",
    "EfficientNetV2S is a smaller variant of the **EfficientNetV2** family, which is an optimized version of EfficientNet, introduced by Google Research in 2021. EfficientNetV2 improves upon its predecessor by using a combination of **fused convolutional layers** and **progressive learning strategies** to achieve better performance with lower computational costs.\n",
    "\n",
    "## Key Features\n",
    "- **Fused Convolutions**: Uses both standard and depthwise convolutions to optimize early-stage processing.\n",
    "- **Smaller and Faster**: Reduces training and inference times while maintaining high accuracy.\n",
    "- **Progressive Learning**: Employs gradual image size scaling during training to improve model generalization.\n",
    "- **Optimized Architecture**: Designed using Neural Architecture Search (NAS) to balance efficiency and accuracy.\n",
    "\n",
    "## Architecture\n",
    "EfficientNetV2S follows a structured architecture with:\n",
    "- **Convolutional and Fused Blocks**: Enhances feature extraction with reduced computational costs.\n",
    "- **SE (Squeeze-and-Excitation) Blocks**: Improves channel-wise feature recalibration.\n",
    "- **MBConv Blocks**: Efficient depthwise convolutions for lower parameter usage.\n",
    "- **Global Average Pooling**: Reduces dimensionality before the fully connected layer.\n",
    "- **Fully Connected Layer**: Final classification output.\n",
    "\n",
    "## Model Usage in TensorFlow/Keras\n",
    "```python\n",
    "from tensorflow.keras.applications import EfficientNetV2S\n",
    "\n",
    "# Load pre-trained EfficientNetV2S model\n",
    "model = EfficientNetV2S(weights='imagenet', include_top=True)\n",
    "model.summary()\n",
    "```\n",
    "\n",
    "## Applications\n",
    "- **Image Classification**: Used in medical imaging, object detection, and large-scale recognition tasks.\n",
    "- **Edge AI and Mobile Deployment**: Due to its efficiency, it is ideal for resource-constrained devices.\n",
    "- **Fine-Tuning for Custom Tasks**: Can be adapted for various specialized vision tasks through transfer learning.\n",
    "\n",
    "EfficientNetV2S is widely adopted for modern deep learning applications, balancing speed and accuracy efficiently.\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.776,
     "end_time": "2021-02-08T01:26:41.641342",
     "exception": false,
     "start_time": "2021-02-08T01:26:40.865342",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ML tools \n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras import layers, Model, optimizers\n",
    "from tensorflow.keras.applications import *\n",
    "import os \n",
    "from skimage.measure import find_contours\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "papermill": {
     "duration": 0.237485,
     "end_time": "2021-02-08T01:26:41.898073",
     "exception": false,
     "start_time": "2021-02-08T01:26:41.660588",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_classes = ['No Finding', 'Cardiomegaly', 'Hernia', 'Infiltration', 'Nodule', 'Emphysema',\n",
    "               'Effusion', 'Atelectasis', 'Pleural_Thickening', 'Pneumothorax',\n",
    "               'Mass', 'Fibrosis', 'Consolidation', 'Edema', 'Pneumonia']\n",
    "target_cols = all_classes\n",
    "df = pd.read_csv('./Usable_data/Data_Entry_2017.csv')\n",
    "df = df[['Image Index','Finding Labels']]\n",
    "df = df.rename(columns = {'Image Index':'img_ind'})\n",
    "\n",
    "# One hot encode diseases\n",
    "for disease in all_classes:\n",
    "    print(\"OHC: \",disease)\n",
    "    df[disease] = np.where(df['Finding Labels'].str.contains(disease), 1,0)\n",
    "\n",
    "# Create paths\n",
    "df['img_ind'] = \"./Usable_data/\" + df['img_ind']\n",
    "df = df.drop(columns = ['Finding Labels'])\n",
    "\n",
    "display(df.head(4))\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We took a mixed sample with single and multiple diseases that appears to be performing well\n",
    "df['Disease Load']  = 1 #df[all_classes].sum(axis = 0)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# Train on a subset of data\n",
    "\n",
    "min_samples_required = 1000\n",
    "\n",
    "labels_df = pd.DataFrame()\n",
    "\n",
    "for disease in all_classes:\n",
    "    \n",
    "    print(\"Finding samples for:\", disease)\n",
    "    \n",
    "    cond_disease_exists = df[disease] == 1\n",
    "    cond_only_this_disease = df['Disease Load'] == 1\n",
    "    all_filters_necessary = cond_disease_exists & cond_only_this_disease\n",
    "    \n",
    "    df_disease = df.loc[all_filters_necessary].reset_index(drop = True)\n",
    "    samples_available = len(df_disease)\n",
    "    print(\"Samples available:\", samples_available)\n",
    "    samples_taken = min(samples_available,min_samples_required)\n",
    "    print(\"Samples taken:\", samples_taken)\n",
    "    selected_sample_df = df_disease.iloc[0:samples_taken,:]\n",
    "    labels_df = pd.concat([labels_df,selected_sample_df], axis=0).reset_index(drop = True)\n",
    "    print(len(labels_df))\n",
    "\n",
    "labels_df = labels_df.drop(columns = ['Disease Load'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = labels_df['img_ind']\n",
    "\n",
    "#Get the multi-labels\n",
    "label_cols = all_classes\n",
    "labels = labels_df[label_cols].values\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Train test split\n",
    "(train_paths, valid_paths, \n",
    "  train_labels, valid_labels) = train_test_split(paths, labels, test_size=0.2, random_state=11)\n",
    "\n",
    "print(train_paths.shape, valid_paths.shape)\n",
    "train_labels.sum(axis=0), valid_labels.sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.027297,
     "end_time": "2021-02-08T01:26:42.266735",
     "exception": false,
     "start_time": "2021-02-08T01:26:42.239438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_classes = len(target_cols)\n",
    "img_size = 600\n",
    "n_epochs = 35\n",
    "lr= 0.0001\n",
    "seed= 11\n",
    "val_split= 0.2\n",
    "seed= 33\n",
    "batch_size=12\n",
    "n_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation for faster ingestion during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.041826,
     "end_time": "2021-02-08T01:26:42.328543",
     "exception": false,
     "start_time": "2021-02-08T01:26:42.286717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def auto_select_accelerator():\n",
    "    try:\n",
    "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "        tf.config.experimental_connect_to_cluster(tpu)\n",
    "        tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "        print(\"Running on TPU:\", tpu.master())\n",
    "    except ValueError:\n",
    "        strategy = tf.distribute.get_strategy()\n",
    "    print(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n",
    "    \n",
    "    return strategy\n",
    "\n",
    "'''\n",
    "Reference\n",
    "https://www.kaggle.com/xhlulu/ranzcr-efficientnet-tpu-training\n",
    "\n",
    "'''\n",
    "\n",
    "def build_decoder(with_labels=True, target_size=(img_size, img_size), ext='jpg'):\n",
    "    def decode(path):\n",
    "        file_bytes = tf.io.read_file(path) # Reads and outputs the entire contents of the input filename.\n",
    "\n",
    "        if ext == 'png':\n",
    "            img = tf.image.decode_png(file_bytes, channels=3) # Decode a PNG-encoded image to a uint8 or uint16 tensor\n",
    "        elif ext in ['jpg', 'jpeg']:\n",
    "            img = tf.image.decode_jpeg(file_bytes, channels=3) # Decode a JPEG-encoded image to a uint8 tensor\n",
    "        else:\n",
    "            raise ValueError(\"Image extension not supported\")\n",
    "\n",
    "        img = tf.cast(img, tf.float32) / 255.0 # Casts a tensor to the type float32 and divides by 255.\n",
    "        img = tf.image.resize(img, target_size) # Resizing to target size\n",
    "        return img\n",
    "    \n",
    "    def decode_with_labels(path, label):\n",
    "        return decode(path), label\n",
    "    \n",
    "    return decode_with_labels if with_labels else decode\n",
    "\n",
    "\n",
    "def build_augmenter(with_labels=True):\n",
    "    def augment(img):\n",
    "        img = tf.image.random_flip_left_right(img)\n",
    "        img = tf.image.random_flip_up_down(img)\n",
    "        img = tf.image.random_saturation(img, 0.8, 1.2)\n",
    "        img = tf.image.random_brightness(img, 0.1)\n",
    "        img = tf.image.random_contrast(img, 0.8, 1.2)\n",
    "        return img\n",
    "    \n",
    "    def augment_with_labels(img, label):\n",
    "        return augment(img), label\n",
    "    \n",
    "    return augment_with_labels if with_labels else augment\n",
    "\n",
    "def build_dataset(paths, labels=None, bsize=32, cache=True,\n",
    "                  decode_fn=None, augment_fn=None,\n",
    "                  augment=True, repeat=True, shuffle=1024, \n",
    "                  cache_dir=\"\"):\n",
    "    if cache_dir != \"\" and cache is True:\n",
    "        os.makedirs(cache_dir, exist_ok=True)\n",
    "    \n",
    "    if decode_fn is None:\n",
    "        decode_fn = build_decoder(labels is not None)\n",
    "    \n",
    "    if augment_fn is None:\n",
    "        augment_fn = build_augmenter(labels is not None)\n",
    "    \n",
    "    AUTO = tf.data.experimental.AUTOTUNE\n",
    "    slices = paths if labels is None else (paths, labels)\n",
    "    \n",
    "    dset = tf.data.Dataset.from_tensor_slices(slices)\n",
    "    dset = dset.map(decode_fn, num_parallel_calls=AUTO)\n",
    "    dset = dset.cache(cache_dir) if cache else dset\n",
    "    dset = dset.map(augment_fn, num_parallel_calls=AUTO) if augment else dset\n",
    "    dset = dset.repeat() if repeat else dset\n",
    "    dset = dset.shuffle(shuffle) if shuffle else dset\n",
    "    dset = dset.batch(bsize).prefetch(AUTO) # overlaps data preprocessing and model execution while training\n",
    "    return dset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 6.314494,
     "end_time": "2021-02-08T01:26:48.663271",
     "exception": false,
     "start_time": "2021-02-08T01:26:42.348777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "strategy = auto_select_accelerator()\n",
    "batch_size = strategy.num_replicas_in_sync * batch_size\n",
    "print('batch size', batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.372349,
     "end_time": "2021-02-08T01:26:49.431926",
     "exception": false,
     "start_time": "2021-02-08T01:26:49.059577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build the tensorflow datasets\n",
    "\n",
    "decoder = build_decoder(with_labels=True, target_size=(img_size, img_size))\n",
    "\n",
    "# Build the tensorflow datasets\n",
    "dtrain = build_dataset(\n",
    "    train_paths, train_labels, bsize=batch_size, decode_fn=decoder\n",
    ")\n",
    "\n",
    "dvalid = build_dataset(\n",
    "    valid_paths, valid_labels, bsize=batch_size, \n",
    "    repeat=False, shuffle=False, augment=False, decode_fn=decoder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, _ = dtrain.take(2)\n",
    "images = data[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 4, figsize=(20,10))\n",
    "axes = axes.flatten()\n",
    "for img, ax in zip(images, axes):\n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building (EfficientNetV2S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.applications import EfficientNetV2S\n",
    "\n",
    "def build_model():\n",
    "    base = EfficientNetV2S(input_shape=(img_size, img_size, 3), include_top=False, weights='imagenet')\n",
    "    \n",
    "    inp = layers.Input(shape=(img_size, img_size, 3))\n",
    "    x = base(inp)\n",
    "    \n",
    "    # Adding additional convolutional layers\n",
    "    x = layers.Conv2D(256, (3,3), activation='relu', padding='same')(x)\n",
    "    x = layers.Conv2D(128, (3,3), activation='relu', padding='same')(x)\n",
    "    x = layers.Conv2D(64, (3,3), activation='relu', padding='same')(x)\n",
    "    \n",
    "    x = layers.GlobalAveragePooling2D()(layers.Dropout(0.16)(x))  # Feature extraction + dropout\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(n_classes, activation='sigmoid')(x)  # Multi-label classification\n",
    "    \n",
    "    return Model(inputs=inp, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model = build_model()\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(label_smoothing=0.0)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "        loss=loss,\n",
    "        metrics=[\n",
    "            tf.keras.metrics.AUC(multi_label=True),\n",
    "            tf.keras.metrics.Precision(),\n",
    "            tf.keras.metrics.Recall(),\n",
    "            tf.keras.metrics.BinaryAccuracy()\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.060939,
     "end_time": "2021-02-08T01:28:52.216709",
     "exception": false,
     "start_time": "2021-02-08T01:28:52.15577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "name = \"NIH_EfficientNetV2S_model.h5\"  # Updated model name\n",
    "\n",
    "# Learning rate reduction on plateau\n",
    "rlr = ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.1, patience=2, verbose=1, \n",
    "    min_delta=1e-4, min_lr=1e-6, mode='min', cooldown=1\n",
    ")\n",
    "\n",
    "# Model checkpoint to save the best model\n",
    "ckp = ModelCheckpoint(\n",
    "    name, monitor='val_loss', verbose=1, save_best_only=True, mode='min'\n",
    ")\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "es = EarlyStopping(\n",
    "    monitor='val_loss', min_delta=1e-4, patience=5, mode='min', \n",
    "    restore_best_weights=True, verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.054513,
     "end_time": "2021-02-08T01:28:52.313072",
     "exception": false,
     "start_time": "2021-02-08T01:28:52.258559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "steps_per_epoch = (train_paths.shape[0] // batch_size)\n",
    "steps_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 4545.439448,
     "end_time": "2021-02-08T02:44:37.790427",
     "exception": false,
     "start_time": "2021-02-08T01:28:52.350979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = model.fit(dtrain,                      \n",
    "                    validation_data=dvalid,                                       \n",
    "                    epochs=n_epochs,\n",
    "                    callbacks=[rlr,es,ckp],\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "name = './AJB_NIH_EfficientNetV2S_model.keras'\n",
    "model.save(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss over epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.74803,
     "end_time": "2021-02-08T02:44:39.033205",
     "exception": false,
     "start_time": "2021-02-08T02:44:38.285175",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 6))\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot( history.history[\"loss\"], label = \"Training Loss\", marker='o')\n",
    "plt.plot( history.history[\"val_loss\"], label = \"Validation Loss\", marker='+')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC-AUC over epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.693171,
     "end_time": "2021-02-08T02:44:40.279118",
     "exception": false,
     "start_time": "2021-02-08T02:44:39.585947",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 6))\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.plot( history.history[\"auc\"], label = \"Training AUC\" , marker='o')\n",
    "plt.plot( history.history[\"val_auc\"], label = \"Validation AUC\", marker='+')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision over epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 6))\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.plot( history.history[\"precision\"], label = \"Training Precision\" , marker='o')\n",
    "plt.plot( history.history[\"val_precision\"], label = \"Validation Precision\", marker='+')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy over epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 6))\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.plot( history.history[\"binary_accuracy\"], label = \"Training Accuracy\" , marker='o')\n",
    "plt.plot( history.history[\"val_binary_accuracy\"], label = \"Validation Accuracy\", marker='+')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall over epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 6))\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.plot( history.history[\"recall\"], label = \"Training Recall\" , marker='o')\n",
    "plt.plot( history.history[\"val_recall\"], label = \"Validation Recall\", marker='+')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training statistics over epochs (in numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_stats = pd.DataFrame(history.history)\n",
    "df_training_stats.to_csv(\"./Training_stats.csv\")\n",
    "df_training_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC by class (i.e. by disease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 501.673242,
     "end_time": "2021-02-08T02:53:02.443459",
     "exception": false,
     "start_time": "2021-02-08T02:44:40.770217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "name = './AJB_NIH_EfficientNetV2S_model.keras'\n",
    "model= tf.keras.models.load_model(name,  safe_mode=False)\n",
    "pred= model.predict(dvalid, verbose=1)\n",
    "\n",
    "print('AUC CHECK-UP per CLASS')\n",
    "\n",
    "classes= all_classes\n",
    "for i, n in enumerate(classes):\n",
    "  print(classes[i])\n",
    "  print(i, roc_auc_score(valid_labels[:, i], pred[:, i]))\n",
    "  print('---------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store results\n",
    "results_auc_classwise = []\n",
    "\n",
    "# Loop through the classes and calculate the ROC AUC scores\n",
    "for i, n in enumerate(all_classes):\n",
    "    auc_score = roc_auc_score(valid_labels[:, i], pred[:, i])\n",
    "    results_auc_classwise.append({\"Class\": n, \"ROC AUC Score\": auc_score})\n",
    "\n",
    "# Convert the list into a pandas DataFrame\n",
    "df_auc_classwise = pd.DataFrame(results_auc_classwise)\n",
    "df_auc_classwise.to_csv(\"./AUC_by_class.csv\", index = False)\n",
    "df_auc_classwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear session to free memory\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model(name, safe_mode=False)\n",
    "\n",
    "# Get model predictions\n",
    "pred = model.predict(dvalid, verbose=1)\n",
    "\n",
    "# Compute AUC scores for each class\n",
    "auc_scores = []\n",
    "for i, n in enumerate(classes):\n",
    "    auc = roc_auc_score(valid_labels[:, i], pred[:, i])\n",
    "    auc_scores.append(auc)\n",
    "\n",
    "# Convert to NumPy array for easy sorting (optional)\n",
    "auc_scores = np.array(auc_scores)\n",
    "\n",
    "# **Plot the AUC scores**\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(classes, auc_scores, color='royalblue')\n",
    "plt.xlabel(\"AUC Score\")\n",
    "plt.ylabel(\"Disease Classes\")\n",
    "plt.title(\"AUC Score per Disease Class\")\n",
    "plt.xlim(0, 1)  # AUC scores range from 0 to 1\n",
    "plt.grid(axis=\"x\", linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "# Annotate bars with values\n",
    "for index, value in enumerate(auc_scores):\n",
    "    plt.text(value + 0.02, index, f\"{value:.3f}\", va=\"center\", fontsize=10)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Clear TensorFlow session\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model(name, safe_mode=False)\n",
    "\n",
    "# Get model predictions\n",
    "pred = model.predict(dvalid, verbose=1)\n",
    "\n",
    "# Initialize figure for multiple ROC curves\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Loop through each disease class and plot its ROC curve\n",
    "for i, disease in enumerate(classes):\n",
    "    fpr, tpr, _ = roc_curve(valid_labels[:, i], pred[:, i])  # Compute FPR, TPR\n",
    "    roc_auc = auc(fpr, tpr)  # Compute AUC\n",
    "    plt.plot(fpr, tpr, label=f\"{disease} (AUC = {roc_auc:.3f})\")  # Plot each ROC curve\n",
    "\n",
    "# Plot diagonal line (random classifier)\n",
    "plt.plot([0, 1], [0, 1], 'k--', label=\"Random (AUC = 0.5)\")\n",
    "\n",
    "# Set axis labels and title\n",
    "plt.xlabel(\"False Positive Rate (FPR)\")\n",
    "plt.ylabel(\"True Positive Rate (TPR)\")\n",
    "plt.title(\"ROC Curves for All Disease Classes\")\n",
    "plt.legend(loc=\"lower right\")  # Add legend\n",
    "plt.grid(alpha=0.3)  # Light grid for better readability\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradcam Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradcam_with_contour(image_path, class_name, model):\n",
    "    all_classes = ['No Finding', 'Cardiomegaly', 'Hernia', 'Infiltration', 'Nodule', 'Emphysema',\n",
    "                   'Effusion', 'Atelectasis', 'Pleural_Thickening', 'Pneumothorax',\n",
    "                   'Mass', 'Fibrosis', 'Consolidation', 'Edema', 'Pneumonia']\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_resized = cv2.resize(img, (img_size, img_size)) / 255.0\n",
    "    img_array = np.expand_dims(img_resized, axis=0)\n",
    "    \n",
    "    preds = model.predict(img_array)[0]\n",
    "    class_idx = all_classes.index(class_name)\n",
    "    class_prob = preds[class_idx]\n",
    "    \n",
    "    # Auto-detect last convolutional layer\n",
    "    for layer in reversed(model.layers):\n",
    "        if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "            last_conv_layer = layer\n",
    "            break\n",
    "    \n",
    "    grad_model = Model(inputs=model.input, outputs=[last_conv_layer.output, model.output])\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_array)\n",
    "        loss = predictions[:, class_idx]\n",
    "    grads = tape.gradient(loss, conv_outputs)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    conv_outputs = conv_outputs[0] * pooled_grads\n",
    "    heatmap = tf.reduce_mean(conv_outputs, axis=-1).numpy()\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    heatmap = heatmap / np.max(heatmap)\n",
    "    \n",
    "    # Generate contours\n",
    "    heatmap_resized = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "    contours = find_contours(heatmap_resized, 0.5)\n",
    "    \n",
    "    # Plot image with contour overlay\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.imshow(img)\n",
    "    for contour in contours:\n",
    "        ax.plot(contour[:, 1], contour[:, 0], linestyle='dotted', color='red', linewidth=2)\n",
    "    \n",
    "    # Add a navy blue bar on top with class name and probability\n",
    "    ax.add_patch(plt.Rectangle((0, 0), img.shape[1], 40, color='grey', alpha=0.8))\n",
    "    ax.text(10, 25, f\"{class_name}: {class_prob:.2f}\", fontsize=14, color='white', weight='bold')\n",
    "    ax.axis('off')\n",
    "\n",
    "    if class_name not in ['No Finding']:\n",
    "        # Save the output image with a new filename\n",
    "        filename = os.path.basename(image_path)\n",
    "        filename_without_ext, ext = os.path.splitext(filename)\n",
    "        output_filename = f\"{filename_without_ext}_{class_name}_CONTOUR{ext}\"\n",
    "        plt.savefig(output_filename, bbox_inches='tight', pad_inches=0)\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"Saved visualization as {output_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradcam_with_heatmap(image_path, class_name, model):\n",
    "    all_classes = ['No Finding', 'Cardiomegaly', 'Hernia', 'Infiltration', 'Nodule', 'Emphysema',\n",
    "                   'Effusion', 'Atelectasis', 'Pleural_Thickening', 'Pneumothorax',\n",
    "                   'Mass', 'Fibrosis', 'Consolidation', 'Edema', 'Pneumonia']\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_resized = cv2.resize(img, (img_size, img_size)) / 255.0\n",
    "    img_array = np.expand_dims(img_resized, axis=0)\n",
    "    \n",
    "    preds = model.predict(img_array)[0]\n",
    "    class_idx = all_classes.index(class_name)\n",
    "    class_prob = preds[class_idx]\n",
    "    \n",
    "    # Auto-detect last convolutional layer\n",
    "    for layer in reversed(model.layers):\n",
    "        if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "            last_conv_layer = layer\n",
    "            break\n",
    "    \n",
    "    grad_model = Model(inputs=model.input, outputs=[last_conv_layer.output, model.output])\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_array)\n",
    "        loss = predictions[:, class_idx]\n",
    "    grads = tape.gradient(loss, conv_outputs)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    conv_outputs = conv_outputs[0] * pooled_grads\n",
    "    heatmap = tf.reduce_mean(conv_outputs, axis=-1).numpy()\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    heatmap = heatmap / np.max(heatmap)\n",
    "    \n",
    "    # Resize heatmap to match the original image\n",
    "    heatmap_resized = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "    heatmap_colored = cv2.applyColorMap(np.uint8(255 * heatmap_resized), cv2.COLORMAP_JET)\n",
    "    superimposed_img = cv2.addWeighted(img, 0.6, heatmap_colored, 0.4, 0)\n",
    "    \n",
    "    # Plot image with heatmap overlay\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.imshow(superimposed_img)\n",
    "    \n",
    "    # Add a navy blue bar on top with class name and probability\n",
    "    ax.add_patch(plt.Rectangle((0, 0), img.shape[1], 60, color='navy', alpha=0.8))\n",
    "    ax.text(10, 25, f\"{class_name}: {class_prob:.2f}\", fontsize=14, color='white', weight='bold')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    if class_name not in ['No Finding']:\n",
    "        # Save the output image with a new filename\n",
    "        filename = os.path.basename(image_path)\n",
    "        filename_without_ext, ext = os.path.splitext(filename)\n",
    "        output_filename = f\"{filename_without_ext}_{class_name}_HEATMAP{ext}\"\n",
    "        plt.savefig(output_filename, bbox_inches='tight', pad_inches=0)\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"Saved visualization as {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = './Usable_data/00000001_001.png'\n",
    "class_name = \"Emphysema\"\n",
    "gradcam_with_contour(image_path, class_name, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradcam_with_heatmap(image_path, class_name, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5839,
     "sourceId": 18613,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 620959,
     "sourceId": 1108231,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1145535,
     "sourceId": 1920904,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1145594,
     "sourceId": 1920987,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30299,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
